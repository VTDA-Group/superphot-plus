{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1011fb76-c186-45a1-aaf0-f862cf2a943f",
   "metadata": {},
   "source": [
    "# Full Train Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e576c-1661-4fba-9a2c-f5d7e5311056",
   "metadata": {},
   "source": [
    "Run when you need to train a new classifier from scratch. Will regenerate transient data, refit all samples, and retrain the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d4adc-97f4-4646-b752-e29e7b2d5f03",
   "metadata": {},
   "source": [
    "## Step 0: Update configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b5c23-342c-40f8-912b-67c3a349503e",
   "metadata": {},
   "source": [
    "In the same folder as this notebook, there is a $\\texttt{config.yaml}$ file, which contains all filepaths and configuration options for the training workflow. Please update this now!\n",
    "\n",
    "The most important filepath arguments are:\n",
    "* $\\texttt{create-dirs}$: Probably keep set to True. Create any data subdirectories that are missing.\n",
    "* $\\texttt{data-dir}$: This is where all generated data is stored. Set to the root directory for all outputs.\n",
    "* $\\texttt{relative-dirs}$: If true, all data for each step is stored within subdirectories of data_dir.\n",
    "* $\\texttt{transient-data-fn}$: This is where all transient data is stored as a TransientGroup. Technically a directory but loaded as a single file. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{sampler-results-fn}$: Where light curve fits are stored. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{figs-dir}$: Where all figures are stored (only generated if $\\texttt{plot}$ is set to True). If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{models-dir}$: Where all classification models are stored. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "\n",
    "The most important sampling and classifier arguments are:\n",
    "* $\\texttt{sampler}$: Set to either dynesty or svi (all lowercase). SVI is faster but forces the posterior into a multivariate Gaussian.\n",
    "* $\\texttt{model-type}$: Set to either LightGBM (recommended) or MLP.\n",
    "* $\\texttt{use-redshift-features}$: If True, includes peak absolute magnitude and redshift as training features.\n",
    "* $\\texttt{fits-per-majority}$: Oversamples such that the majority class has this many samples fed into the classifier. Minority classes will correspond to more input samples per event. Defaults to 5.\n",
    "* $\\texttt{target-label}$: For binary classification - this is the positive label. Set to None for multiclass classification.\n",
    "* $\\texttt{n-folds}$: Number of K-folds. I usually set to 10.\n",
    "* $\\texttt{num-epochs}$: Number of estimators for LightGBM or number of training epochs for MLP.\n",
    "* $\\texttt{n-parallel}$: Number of threads to parallelize data import + sampling over.\n",
    "* $\\texttt{random-seed}$: For reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef53e57-bef4-4755-94b1-477a7d6620ec",
   "metadata": {},
   "source": [
    "## Step 1: Generate new TransientSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06baa7f-5374-448d-acdb-8bbc5404a387",
   "metadata": {},
   "source": [
    "Here we will import data from TNS + ALeRCE and generate a new TransientSet, from a list of event names. Names can be from TNS or ZTF.\n",
    "\n",
    "The below code block will retrieve all spectroscopically classified TNS transients. Feel free to change to your own list of names or import script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79328b-94f8-4bd6-8cd7-885799db4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from snapi.query_agents import TNSQueryAgent\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "print(SAVE_DIR)\n",
    "\n",
    "tns_agent = TNSQueryAgent(db_path=SAVE_DIR)\n",
    "#tns_agent.update_local_database() # IMPORTANT: run this line if first time using SNAPI or if you want to reimport TNS csv\n",
    "all_names = tns_agent.retrieve_all_names() # only spectroscopically classified\n",
    "all_names = [x for x in all_names if int(x[:4]) > 2018] # because pre-2019 templates are pretty bad\n",
    "print(len(all_names), all_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc3dda-d71f-4da0-9a68-59526d0916ad",
   "metadata": {},
   "source": [
    "The following script will import data for all provided names and generate a TransientGroup object. Will run in parallel across n_cores threads.\n",
    "\n",
    "For the entire TNS dataset (~16000 events), this takes ~30 minutes on 8 parallel cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718f0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First augments the config file to save to your data folder path!\n",
    "# Feel free to change to any path you want\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "config.update(data_dir=SAVE_DIR)\n",
    "config.write_to_file('config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8f8548-4c29-44aa-b14a-a9b1432e264b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.data_generation import import_all_names\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "save_dir = config.transient_data_fn\n",
    "\n",
    "# import data for all_names from query agents\n",
    "import_all_names(\n",
    "    all_names, save_dir,\n",
    "    checkpoint_freq=512,\n",
    "    n_cores=config.n_parallel,\n",
    "    overwrite=True,\n",
    "    skipped_names_fn = os.path.join(config.data_dir, \"skipped_names.txt\"),\n",
    "    tns_db_path=SAVE_DIR,\n",
    ") # set overwrite=False to continue from where left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8332fc7c-1f2f-42ce-a9c2-38c8dbc9db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the TransientGroup we created!\n",
    "from snapi import TransientGroup\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "transient_group.add_col('peak_abs_mag', lambda x: x.peak_abs_mag)\n",
    "print(len(transient_group.metadata))\n",
    "print(transient_group.metadata.head())\n",
    "print(transient_group.metadata.groupby('spec_class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e95c4-e3aa-4978-8a45-b5e248ea6310",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 (Option 1): Fit all transients using SVI (faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2e7f9-a9bd-4c61-80ab-9c88f2252c90",
   "metadata": {},
   "source": [
    "Here, we choose to fit our transients using stochastic variational inference (SVI). If using this option, make sure sampler='superphot_svi' in the config.yaml file. This option is faster but assumes Gaussianity of the posterior space, which can be limiting for certain light curve fits.\n",
    "\n",
    "For all ~8300 TNS transients passing quality cuts, this takes ~30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06532f86-feb2-45da-ab33-49966d1f14d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_transient_group\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "priors = SuperphotPrior.load('priors/global_priors_hier_svi')\n",
    "\n",
    "#priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "priors = SuperphotPrior.load(SAVE_DIR + \"/\" + \"global_priors_hier_svi\")\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_iter=10_000,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "result = fit_transient_group(\n",
    "    transient_group,\n",
    "    sampler = svi_sampler,\n",
    "    parallelize=True,\n",
    "    n_parallel=config.n_parallel,\n",
    "    checkpoint_fn = os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    "    checkpoint_freq = 512,\n",
    "    pad=True,\n",
    "    overwrite=True # set to False to continue where left off\n",
    ")\n",
    "SamplerResultGroup(result).save(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9646f8-e84d-4ebb-97e2-9896fbed67a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import TransientGroup, SamplerResultGroup, Formatter\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_iter=10_000,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "names = sampler_results.metadata.index\n",
    "\n",
    "formatter = Formatter()\n",
    "for n in names[-5:]:\n",
    "    t = transient_group[n] # can index like dictionary\n",
    "    sr = sampler_results[n]\n",
    "    svi_sampler.load_result(sr)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    svi_sampler.plot_fit(\n",
    "        ax,\n",
    "        photometry = t.photometry,\n",
    "        formatter = formatter,\n",
    "    )\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    t.photometry.plot(\n",
    "        ax,\n",
    "        mags=False,\n",
    "        formatter=formatter\n",
    "    )\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax)\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5600e",
   "metadata": {},
   "source": [
    "## Step 2a: Hierarchical Bayesian Inference (slowest)\n",
    "Optimize priors hierarchically for the dataset. Uses subset (~500) of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87903831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_many_hierarchical\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "priors = generate_priors(\n",
    "    [\"ZTF_r\", \"ZTF_g\"],\n",
    "    priors_dir='priors',\n",
    ")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(len(transient_group))\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_events=500,\n",
    "    num_iter=20_000,\n",
    "    step_size=0.01,\n",
    "    random_state=42,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "global_priors, indiv_results = fit_many_hierarchical(\n",
    "    transient_group,\n",
    "    500,\n",
    "    svi_sampler,\n",
    "    pad=False\n",
    ")\n",
    "global_priors[0].save(\"hierarchical_svi_global_loc\")\n",
    "global_priors[1].save(\"hierarchical_svi_global_scale\")\n",
    "srg_indiv = SamplerResultGroup(indiv_results)\n",
    "srg_indiv.save(\"hierarchical_svi_srg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9fb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from snapi import SamplerResult\n",
    "import os\n",
    "\n",
    "# convert global SRs to new prior files\n",
    "all_bands = [\"ZTF_r\", \"ZTF_g\",]\n",
    "priors = generate_priors(\n",
    "    all_bands,\n",
    "    priors_dir='priors',\n",
    ")\n",
    "global_prior_mu = SamplerResult.load(\"hierarchical_svi_global_loc\")\n",
    "gauss_prior_mu = priors.reverse_transform(global_prior_mu.fit_parameters)\n",
    "global_prior_sigma = SamplerResult.load(\"hierarchical_svi_global_scale\")\n",
    "gauss_prior_sigma = priors.reverse_transform(global_prior_sigma.fit_parameters)\n",
    "\n",
    "df = priors.dataframe.copy()\n",
    "\n",
    "all_params = df['param']\n",
    "df.loc[:, 'mean'] = gauss_prior_mu[all_params].mean(axis=0).to_numpy()\n",
    "df.loc[:, 'stddev'] = gauss_prior_sigma[all_params].mean(axis=0).to_numpy()\n",
    "\n",
    "print(df)\n",
    "\n",
    "global_priors = SuperphotPrior(df)\n",
    "\n",
    "global_priors.save(\"priors/global_priors_hier_svi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4ce7d-b8ad-402f-8d3a-84fc21fb9b85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 (Option 2): Fit light curves using dynesty (slower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a2595-fc7d-46ab-bd7f-d2d753e94c3f",
   "metadata": {},
   "source": [
    "Here, we fit our transient photometry using the dynesty nested sampler. This is slower but does not assume Gaussianity of the posterior space, so can better capture degeneracies between parameters. If you use this, make sure to set sampler=superphot_dynesty in the config.yaml file.\n",
    "\n",
    "Runtime for 7202 TNS samples: ~200 minutes (3.5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3810-fd87-4257-9682-ba600fe2d0b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_transient_group\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "#priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "priors = SuperphotPrior.load(SAVE_DIR + \"/\" + \"global_priors_hier_svi\")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"], priors_dir='priors')\n",
    "\n",
    "dynesty_sampler = DynestySampler(\n",
    "    priors=priors,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "result = fit_transient_group(\n",
    "    transient_group,\n",
    "    sampler = dynesty_sampler,\n",
    "    parallelize=True,\n",
    "    n_parallel=config.n_parallel,\n",
    "    checkpoint_fn = os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    "    checkpoint_freq = 128,\n",
    "    pad=False,\n",
    "    overwrite=True, # False to continue from checkpoint\n",
    ")\n",
    "SamplerResultGroup(result).save(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e8afc-964a-4cfd-86e4-818f14eb874a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import TransientGroup, SamplerResultGroup, Formatter\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "\n",
    "svi_sampler = DynestySampler(\n",
    "    priors=priors,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "names = sampler_results.metadata.index\n",
    "\n",
    "formatter = Formatter()\n",
    "for n in names[-5:]: # neweet \n",
    "    t = transient_group[n] # can index like dictionary\n",
    "    sr = sampler_results[n]\n",
    "    svi_sampler.load_result(sr)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    svi_sampler.plot_fit(\n",
    "        ax,\n",
    "        photometry = t.photometry,\n",
    "        formatter = formatter,\n",
    "    )\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    t.photometry.plot(\n",
    "        ax,\n",
    "        mags=False,\n",
    "        formatter=formatter\n",
    "    )\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax)\n",
    "\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3bf32-e38c-4bf9-874f-c77a9bd19610",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2.5: Convert SamplerResultGroup posteriors back to uncorrelated Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c543bc2-98a5-403f-9bde-d487bb9d02cf",
   "metadata": {},
   "source": [
    "When sampling, the posteriors are saved as the inputs to our flux model. The Gaussian priors, however, were converted to log-Gaussians and multiplied by base parameters where necessary before being fed into the model function. Therefore, we must revert these log-Gaussian and relative parameters back to their original uncorrelated Gaussian draws before using as classifier inputs. We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dacf611-9d09-4e09-9999-95c5975675e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: only run once!\n",
    "import os\n",
    "from snapi import SamplerResultGroup, TransientGroup\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# also add peak_abs_mag column\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "\n",
    "new_sr = []\n",
    "for i, sr in enumerate(sampler_results):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Converted {i} out of {len(sampler_results)} fits\")\n",
    "    n = sr.id\n",
    "    transient = transient_group[n]    \n",
    "    params = priors.reverse_transform(sr.fit_parameters)\n",
    "    params['peak_abs_mag'] = transient.peak_abs_mag\n",
    "    sr.fit_parameters = params\n",
    "    new_sr.append(sr)\n",
    "    \n",
    "new_sampler_results = SamplerResultGroup(new_sr)\n",
    "new_sampler_results.save(config.sampler_results_fn)\n",
    "\n",
    "print(new_sampler_results.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b9d28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make summary df and all samples\n",
    "import os\n",
    "from snapi import SamplerResultGroup, TransientGroup\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "import os\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "metadata = srg.metadata\n",
    "metadata.to_csv(os.path.join(config.data_dir, \"all_samples.csv\"))\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128b82d-9162-47c1-adf9-4fe3a65a305b",
   "metadata": {},
   "source": [
    "## Step 3: Train + evaluate classifier from sampling posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb48bb5-24ed-4017-8b29-fca16da4e049",
   "metadata": {},
   "source": [
    "Here we train a classifier with our uncorrelated posterior features. This script will automatically split the data into K-folds, oversample the training and validation sets to even out minority classes, and train either LightGBMs (recommended) or MLPs. If plot is True, metric plots and confusion matrices will also be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9076c371-e919-4dc8-807c-b2aa585776dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "# remove A_ZTF_r and t_0_ZTF_r from params used in classification - see paper for details\n",
    "metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "keep_cols = metadata.drop(\n",
    "    columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    ").columns\n",
    "config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols]\n",
    "print(config.input_features)\n",
    "\n",
    "# train classifier\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.config.input_features = [\n",
    "    #\"A_ZTF_r\",\n",
    "    #\"peak_abs_mag\",\n",
    "    \"beta_ZTF_r\",\n",
    "    \"gamma_ZTF_r\",\n",
    "    \"tau_rise_ZTF_r\",\n",
    "    \"tau_fall_ZTF_r\",\n",
    "    \"extra_sigma_ZTF_r\",\n",
    "    \"A_ZTF_g\",\n",
    "    \"beta_ZTF_g\",\n",
    "    \"gamma_ZTF_g\",\n",
    "    \"t_0_ZTF_g\",\n",
    "    \"tau_rise_ZTF_g\",\n",
    "    \"tau_fall_ZTF_g\",\n",
    "    \"extra_sigma_ZTF_g\",\n",
    "]\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90d6f4",
   "metadata": {},
   "source": [
    "Finally, we train a version of the classifier without a test set (aka we use the entire dataset in training or validation). This is what we'll be using to classify a new, disparate dataset.\n",
    "\n",
    "In addition to the classic full-phase classifier, we train a classifier that only uses early-phase features (excludes plateau durations and fall timescales). This is more effective at classifying partial supernova light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc790c91-898a-4e3f-b94c-c96377e448af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "# remove A_ZTF_r and t_0_ZTF_r from params used in classification - see paper for details\n",
    "metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "keep_cols = metadata.drop(\n",
    "    columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    ").columns\n",
    "config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols]\n",
    "print(config.input_features)\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.setup_model()\n",
    "meta_df = trainer.retrieve_transient_metadata(transient_group)\n",
    "train_df, val_df = trainer.split(meta_df, split_frac=0.1)\n",
    "\n",
    "train_srg = srg.filter(train_df.index)\n",
    "val_srg = srg.filter(val_df.index)\n",
    "\n",
    "\n",
    "# train full-type\n",
    "trainer.config.input_features = [\n",
    "    \"beta_ZTF_r\",\n",
    "    \"gamma_ZTF_r\",\n",
    "    \"tau_rise_ZTF_r\",\n",
    "    \"tau_fall_ZTF_r\",\n",
    "    \"extra_sigma_ZTF_r\",\n",
    "    \"A_ZTF_g\",\n",
    "    \"beta_ZTF_g\",\n",
    "    \"gamma_ZTF_g\",\n",
    "    \"t_0_ZTF_g\",\n",
    "    \"tau_rise_ZTF_g\",\n",
    "    \"tau_fall_ZTF_g\",\n",
    "    \"extra_sigma_ZTF_g\",\n",
    "]\n",
    "trainer.train(0, (train_df, train_srg), (val_df, val_srg))\n",
    "trainer.models[0].save(config.model_prefix + \"_full\")\n",
    "print(trainer.models[0].best_model.feature_name_)\n",
    "\n",
    "probs_avg = trainer.evaluate(0, (meta_df, srg))\n",
    "probs_avg[['SLSN-I', 'SN II', 'SN Ia', 'SN Ibc', 'SN IIn']] = probs_avg[['SLSN-I', 'SN II', 'SN Ia', 'SN Ibc', 'SN IIn']].round(2)\n",
    "probs_avg['max_prob'] = probs_avg[['SLSN-I', 'SN II', 'SN Ia', 'SN Ibc', 'SN IIn']].max(axis=1)\n",
    "probs_avg.drop(columns=['true_class','fold'], inplace=True)\n",
    "probs_avg.to_csv(\"/Users/kdesoto/superphot-plus-data/probs_phot_full.csv\")\n",
    "\n",
    "print(\"Full results saved\")\n",
    "# train early-type\n",
    "metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "keep_cols = metadata.drop(\n",
    "    columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    ").columns\n",
    "trainer.config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols if (\n",
    "        ('tau_fall' not in c) and ('gamma' not in c)\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer.train(1, (train_df, train_srg), (val_df, val_srg))\n",
    "trainer.models[1].save(config.model_prefix + \"_early\")\n",
    "print(trainer.models[1].best_model.feature_name_)\n",
    "\n",
    "probs_avg = trainer.evaluate(1, (meta_df, srg))\n",
    "probs_avg.to_csv(config.probs_fn[:-4] + \"_early.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540b525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
